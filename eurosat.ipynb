{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eurosat.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "!pip install -qU tensorflow_datasets\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "WuUPMUPuArvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UYplUwu9FN5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "def set_seeds(seed=SEED):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "def set_global_determinism(seed=SEED):\n",
        "    set_seeds(seed=seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "\n",
        "\n",
        "set_global_determinism(seed=SEED)\n",
        "\n",
        "try:\n",
        "    # TPU config\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    auto = tf.data.experimental.AUTOTUNE\n",
        "    replicas = strategy.num_replicas_in_sync\n",
        "    print(f'TPU: {tpu.master()}')\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    auto = tf.data.experimental.AUTOTUNE\n",
        "    replicas = strategy.num_replicas_in_sync\n",
        "\n",
        "# XLA acceleartion\n",
        "tf.config.optimizer.set_jit(True)\n",
        "print(f'Replicas: {replicas}')\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiUO6lvTDXjs",
        "outputId": "b6c58482-8412-4f1c-93a5-2b3151c65a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replicas: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tfds.show_examples(ds, ds_info)"
      ],
      "metadata": {
        "id": "ZGNyct7TA_jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run =   {\n",
        "    \"name\": \"resnet_model\",\n",
        "    \"epochs\": 10,\n",
        "    \"iterations\": 1,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 3e-4,\n",
        "    \"class_weights\": False,\n",
        "    \"layer_sizes\": [\n",
        "      1024,\n",
        "      512,\n",
        "      128\n",
        "    ],\n",
        "    \"dropout_factor\": 0.3\n",
        "  }"
      ],
      "metadata": {
        "id": "9tLR0U_2KNU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, info = tfds.load('eurosat/all',\n",
        "                        with_info=True,\n",
        "                        split='train',\n",
        "                        batch_size=-1,\n",
        "                        data_dir = DATA_DIR\n",
        "                        )\n",
        "\n",
        "X = tfds.as_numpy(train['image'])\n",
        "y = tfds.as_numpy(train['label'])\n",
        "\n",
        "# Encode labels\n",
        "y_cat = to_categorical(y, num_classes=10)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, random_state=0)"
      ],
      "metadata": {
        "id": "5Rrb1orPBlMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OraxswUBaI-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_model(run, img_input_shape=(500, 500, 3), n_labels=10):\n",
        "    inputs = layers.Input(shape=img_input_shape)\n",
        "    resnet = tf.keras.applications.resnet50.ResNet50(\n",
        "        include_top=False, weights='imagenet', input_tensor=inputs,\n",
        "        input_shape=img_input_shape, pooling='avg')\n",
        "    for i in resnet.layers:\n",
        "        i.trainable = False\n",
        "    x = resnet(inputs)\n",
        "    x = layers.Dense(run['layer_sizes'][0], activation='relu')(x)\n",
        "    x = layers.Dropout(run['dropout_factor'])(x)\n",
        "    x = layers.Dense(run['layer_sizes'][1], activation='relu')(x)\n",
        "    x = layers.Dropout(run['dropout_factor'])(x)\n",
        "    x = layers.Dense(run['layer_sizes'][2], activation='relu')(x)\n",
        "    x = layers.Dropout(run['dropout_factor'])(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(n_labels, activation='sigmoid', name='output')(x)\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[output])\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8DQdr52ECHfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "uN9USvH3CmHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet_model(run)\n"
      ],
      "metadata": {
        "id": "rlV2iYmtCRRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds(SEED)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "\n",
        "# data = DataLoader(data_dir, img_height=img_height, img_width=img_width)\n",
        "\n",
        "# if run['class_weights']:\n",
        "#     n = data.train_generator.samples\n",
        "#     n_0 = n - sum(data.train_generator.labels)\n",
        "#     n_1 = sum(data.train_generator.labels)\n",
        "#     weight_for_0 = (1 / n_0) * (n / 2.0)\n",
        "#     weight_for_1 = (1 / n_1) * (n / 2.0)\n",
        "#     class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "# else:\n",
        "#     class_weight = {0: 1, 1: 1}\n",
        "if run['name'] == 'resnet_model':\n",
        "    model = resnet_model(run, img_input_shape=(img_height, img_width, 3))\n",
        "# elif run_dict['name'] == 'vgg_model':\n",
        "#     model = vgg_model(run_dict, img_input_shape=(img_height, img_width, 3))\n",
        "else:\n",
        "    raise ValueError('Use different model')\n",
        "\n",
        "loss = tf.keras.losses.categorical_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=run['learning_rate'])\n",
        "metrics = [tf.keras.metrics.BinaryAccuracy(name='test_accuracy'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.FalseNegatives(name='fn'),\n",
        "            tf.keras.metrics.FalsePositives(name='fp'),\n",
        "            tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "            tf.keras.metrics.TruePositives(name='tp')]\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics)\n",
        "# log_dir = os.path.join(workdir,\n",
        "#                         \"log_v2/fit/\" + run['name'] + f\"/{'_'.join([str(x) for x in run.values()])}\")\n",
        "\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=1e-3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data = [X_test, y_test], epochs=run['epochs'],\n",
        "                    callbacks=[early_stopping], verbose=2)\n"
      ],
      "metadata": {
        "id": "-7z_099eC_4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_test_flat = np.argmax(y_test, axis=-1)\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "\n",
        "print(classification_report(y_test_flat, y_pred, target_names=labels))"
      ],
      "metadata": {
        "id": "XW0tKT5JTwQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(y_test_flat, y_pred,\n",
        "                              display_labels=labels, ax=ax)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "\n",
        "# NOTE: Fill all variables here with default values of the plot_confusion_matrix\n",
        "# disp.plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBR-o7TNQzn2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}