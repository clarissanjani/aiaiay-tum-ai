{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eurosat.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMlgwLXmV0Y83ZHsMsTJEFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clarissanjani/aiaiay-tum-ai/blob/main/eurosat_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "!pip install -qU tensorflow_datasets\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "WuUPMUPuArvD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UYplUwu9FN5f"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "def set_seeds(seed=SEED):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "def set_global_determinism(seed=SEED):\n",
        "    set_seeds(seed=seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    tf.config.threading.set_inter_op_parallelism_threads(1)\n",
        "    tf.config.threading.set_intra_op_parallelism_threads(1)\n",
        "\n",
        "\n",
        "set_global_determinism(seed=SEED)\n",
        "\n",
        "try:\n",
        "    # TPU config\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    auto = tf.data.experimental.AUTOTUNE\n",
        "    replicas = strategy.num_replicas_in_sync\n",
        "    print(f'TPU: {tpu.master()}')\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    auto = tf.data.experimental.AUTOTUNE\n",
        "    replicas = strategy.num_replicas_in_sync\n",
        "\n",
        "# XLA acceleartion\n",
        "tf.config.optimizer.set_jit(True)\n",
        "print(f'Replicas: {replicas}')\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiUO6lvTDXjs",
        "outputId": "85b7b970-752f-4663-8842-fd31154b5cde"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Replicas: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tfds.show_examples(ds, ds_info)"
      ],
      "metadata": {
        "id": "ZGNyct7TA_jn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run =   {\n",
        "    \"name\": \"resnet_model\",\n",
        "    \"epochs\": 10,\n",
        "    \"iterations\": 1,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 3e-4,\n",
        "    \"class_weights\": False,\n",
        "    \"layer_sizes\": [\n",
        "      1024,\n",
        "      512,\n",
        "      128\n",
        "    ],\n",
        "    \"dropout_factor\": 0.3\n",
        "  }"
      ],
      "metadata": {
        "id": "9tLR0U_2KNU1"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = './eurosat'\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, info = tfds.load('eurosat/rgb',\n",
        "                        with_info=True,\n",
        "                        split='train',\n",
        "                        batch_size=-1,\n",
        "                        data_dir = DATA_DIR\n",
        "                        )\n",
        "\n",
        "X = tfds.as_numpy(train['image'])\n",
        "y = tfds.as_numpy(train['label'])\n",
        "\n",
        "# Encode labels\n",
        "y_cat = to_categorical(y, num_classes=10)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, random_state=0)"
      ],
      "metadata": {
        "id": "5Rrb1orPBlMz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfds.show_examples(train, info)"
      ],
      "metadata": {
        "id": "OraxswUBaI-k"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_model(run, img_input_shape=(500, 500, 3), n_labels=10):\n",
        "    inputs = layers.Input(shape=img_input_shape)\n",
        "    resnet = tf.keras.applications.resnet50.ResNet50(\n",
        "        include_top=False, weights='imagenet', input_tensor=inputs,\n",
        "        input_shape=img_input_shape, pooling='avg')\n",
        "    for i in resnet.layers:\n",
        "        i.trainable = False\n",
        "    x = resnet(inputs)\n",
        "    x = layers.Dense(run['layer_sizes'][0], activation='relu')(x)\n",
        "    x = layers.Dropout(run['dropout_factor'])(x)\n",
        "    x = layers.Dense(run['layer_sizes'][1], activation='relu')(x)\n",
        "    x = layers.Dropout(run['dropout_factor'])(x)\n",
        "    x = layers.Dense(run['layer_sizes'][2], activation='relu')(x)\n",
        "    x = layers.Dropout(run['dropout_factor'])(x)\n",
        "\n",
        "    output = tf.keras.layers.Dense(n_labels, activation='sigmoid', name='output')(x)\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=[output])\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8DQdr52ECHfI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "uN9USvH3CmHM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet_model(run)\n"
      ],
      "metadata": {
        "id": "rlV2iYmtCRRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3659a7b5-4a6d-466c-c0d4-98563b2d21e0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 500, 500, 3)]     0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,277,642\n",
            "Trainable params: 2,689,930\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds(SEED)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "img_height = 64\n",
        "img_width = 64\n",
        "\n",
        "# data = DataLoader(data_dir, img_height=img_height, img_width=img_width)\n",
        "\n",
        "# if run['class_weights']:\n",
        "#     n = data.train_generator.samples\n",
        "#     n_0 = n - sum(data.train_generator.labels)\n",
        "#     n_1 = sum(data.train_generator.labels)\n",
        "#     weight_for_0 = (1 / n_0) * (n / 2.0)\n",
        "#     weight_for_1 = (1 / n_1) * (n / 2.0)\n",
        "#     class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "# else:\n",
        "#     class_weight = {0: 1, 1: 1}\n",
        "if run['name'] == 'resnet_model':\n",
        "    model = resnet_model(run, img_input_shape=(img_height, img_width, 3))\n",
        "# elif run_dict['name'] == 'vgg_model':\n",
        "#     model = vgg_model(run_dict, img_input_shape=(img_height, img_width, 3))\n",
        "else:\n",
        "    raise ValueError('Use different model')\n",
        "\n",
        "loss = tf.keras.losses.categorical_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=run['learning_rate'])\n",
        "metrics = [tf.keras.metrics.CategoricalAccuracy(name='test_accuracy'),\n",
        "            tf.keras.metrics.AUC()]\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics)\n",
        "# log_dir = os.path.join(workdir,\n",
        "#                         \"log_v2/fit/\" + run['name'] + f\"/{'_'.join([str(x) for x in run.values()])}\")\n",
        "\n",
        "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=1e-3,\n",
        "                                                  restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data = [X_test, y_test], epochs=run['epochs'],\n",
        "                    callbacks=[early_stopping], verbose=2)\n"
      ],
      "metadata": {
        "id": "-7z_099eC_4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300b3ad8-d0c5-4107-a0c6-f08b8341122e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,277,642\n",
            "Trainable params: 2,689,930\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "633/633 - 37s - loss: 0.6056 - test_accuracy: 0.8119 - auc: 0.9529 - val_loss: 0.2905 - val_test_accuracy: 0.9044 - val_auc: 0.9834 - 37s/epoch - 59ms/step\n",
            "Epoch 2/10\n",
            "633/633 - 24s - loss: 0.3305 - test_accuracy: 0.8942 - auc: 0.9709 - val_loss: 0.2279 - val_test_accuracy: 0.9244 - val_auc: 0.9832 - 24s/epoch - 39ms/step\n",
            "Epoch 3/10\n",
            "633/633 - 29s - loss: 0.2571 - test_accuracy: 0.9153 - auc: 0.9686 - val_loss: 0.2080 - val_test_accuracy: 0.9321 - val_auc: 0.9809 - 29s/epoch - 45ms/step\n",
            "Epoch 4/10\n",
            "633/633 - 18s - loss: 0.2107 - test_accuracy: 0.9296 - auc: 0.9657 - val_loss: 0.2314 - val_test_accuracy: 0.9270 - val_auc: 0.9711 - 18s/epoch - 28ms/step\n",
            "Epoch 5/10\n",
            "633/633 - 18s - loss: 0.1892 - test_accuracy: 0.9361 - auc: 0.9617 - val_loss: 0.2171 - val_test_accuracy: 0.9314 - val_auc: 0.9715 - 18s/epoch - 28ms/step\n",
            "Epoch 6/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def solver(run):\n",
        "#   loss = tf.keras.losses.categorical_crossentropy\n",
        "#   optimizer = tf.keras.optimizers.Adam(learning_rate=run['learning_rate'])\n",
        "#   metrics = [tf.keras.metrics.CategoricalAccuracy(name='test_accuracy'),\n",
        "#               tf.keras.metrics.AUC()]\n",
        "#   model.compile(\n",
        "#       optimizer=optimizer,\n",
        "#       loss=loss,\n",
        "#       metrics=metrics)\n",
        "#   # log_dir = os.path.join(workdir,\n",
        "#   #                         \"log_v2/fit/\" + run['name'] + f\"/{'_'.join([str(x) for x in run.values()])}\")\n",
        "\n",
        "#   # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "#   early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, min_delta=1e-3,\n",
        "#                                                     restore_best_weights=True)\n",
        "\n",
        "#   history = model.fit(X_train, y_train, validation_data = [X_test, y_test], epochs=run['epochs'],\n",
        "#                       callbacks=[early_stopping], verbose=2)\n",
        "#   y_test_flat = np.argmax(y_test, axis=-1)\n",
        "#   y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "#   return claculate_some_metric(y_test_flat, y_pred)"
      ],
      "metadata": {
        "id": "Lxj4fIZh7FFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_test_flat = np.argmax(y_test, axis=-1)\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "labels = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
        "       'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River',\n",
        "       'SeaLake']\n",
        "\n",
        "print(classification_report(y_test_flat, y_pred, target_names=labels))"
      ],
      "metadata": {
        "id": "XW0tKT5JTwQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_predictions(y_test_flat, y_pred,\n",
        "                              display_labels=labels, ax=ax)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "\n",
        "# NOTE: Fill all variables here with default values of the plot_confusion_matrix\n",
        "# disp.plot()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBR-o7TNQzn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "from io import StringIO\n",
        "import io\n",
        "from PIL import Image\n",
        "from math import log, exp, tan, atan, pi, ceil\n",
        "import requests\n",
        "from image_helpers import sliding_window\n",
        "\n",
        "level_dict = {\n",
        "  19 : 1128.497220,\n",
        "  18 : 2256.994440,\n",
        "  17 : 4513.988880,\n",
        "  16 : 9027.977761,\n",
        "  15 : 18055.955520,\n",
        "  14 : 36111.911040,\n",
        "  13 : 72223.822090,\n",
        "  12 : 144447.644200,\n",
        "  11 : 288895.288400,\n",
        "  10 : 577790.576700,\n",
        "  9 : 1155581.153000,\n",
        "  8  : 2311162.307000,\n",
        "  7  : 4622324.614000,\n",
        "  6  : 9244649.227000,\n",
        "  5  : 18489298.450000,\n",
        "  4  : 36978596.910000,\n",
        "  3  : 73957193.820000,\n",
        "  2  : 147914387.600000,\n",
        "  1  : 295828775.300000,\n",
        "  0  : 591657550.500000\n",
        "}\n",
        "\n",
        "\n",
        "urlparams = urllib.parse.urlencode({'center': ','.join((str(48.1371079), str(11.5753822))),\n",
        "                                      'zoom': 14,\n",
        "                                      'size': '640x640',\n",
        "                                      'maptype': 'satellite',\n",
        "                                      'sensor': 'false',\n",
        "                                      'scale': 1, \n",
        "                                      'key': 'AIzaSyA4QuvbHhh74WAVWc_rpCJNbywBGRWL5qU'}, \n",
        "                                      )\n",
        "        \n",
        "url = 'http://maps.google.com/maps/api/staticmap?' + urlparams\n",
        "f=urllib.request.urlopen(url)\n",
        "response = requests.get(url)\n",
        "im=Image.open(io.BytesIO(response.content))\n",
        "im.save('pic.png')\n",
        "x = Image.open('pic.png')\n",
        "plt.imshow(im)\n",
        "plt.show()\n",
        "image = im.convert(\"RGB\")\n",
        "image = np.asarray(image, dtype=np.uint8)\n",
        "image = image[:, :, :3]\n",
        "t = [0 for x in range(100)]\n",
        "for i, (x, y, window) in enumerate(sliding_window(image, stepSize=64, windowSize=(64, 64))):\n",
        "  t[i] = np.argmax(model.predict(window[np.newaxis, :]), axis=-1)\n",
        "\n",
        "import cv2\n",
        "\n",
        "k_small = np.array(t).reshape(10, 10)\n",
        "plt.imshow(k_small)\n",
        "plt.show()\n",
        "# k = Image.fromarray((k).astype(np.uint8))\n",
        "# gray = cv2.cvtColor(np.float32(imgUMat), cv2.COLOR_RGB2GRAY)\n",
        "k = cv2.resize(k_small,(640,640),fx=0, fy=0, interpolation = cv2.INTER_NEAREST)\n",
        "# image = t.convert(\"RGB\")\n",
        "# image_new = np.asarray(k, dtype=np.uint8)\n",
        "# image = image[:, :]/\n",
        "import matplotlib.patches as mpatches\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "ax.imshow(image)\n",
        "im = ax.imshow(k, alpha=0.5, cmap='Set1')\n",
        "values = np.unique(k.ravel())\n",
        "colors = [ im.cmap(im.norm(value)) for value in range(10)]\n",
        "# create a patch (proxy artist) for every color \n",
        "patches = [ mpatches.Patch(color=colors[i], label=l)  for i, l in enumerate(labels) ]\n",
        "# put those patched as legend-handles into the legend\n",
        "plt.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0. )\n",
        "\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Yh-X4KY15Ymm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from coordinate_helpers import G_LatLng, getCorners\n",
        "\n",
        "centerPoint = G_LatLng(48.1371079, 11.5753822)\n",
        "edges =getCorners(centerPoint, 14, 640, 640)\n",
        "\n",
        "min_lon = edges['W']  # 45°58'32.27\"W\n",
        "max_lon = edges['E']   # 45°57'54.54\"W\n",
        "min_lat = edges['N']   # 23°47' 7.65\"S\n",
        "max_lat = edges['S']   # 23°46'42.25\"S\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v7bINXtaW5C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import json\n",
        "import numpy as np\n",
        "from folium.plugins import FloatImage\n",
        "from coordinate_helpers import pointiterator\n",
        "import base64\n",
        "\n",
        "xiter = pointiterator(edges['W'],edges['E'],10)\n",
        "yiter = pointiterator(edges['S'],edges['N'],10)\n",
        "xx=np.fromiter(xiter,dtype=np.float)\n",
        "print(xx)\n",
        "yy=np.fromiter(yiter,dtype=np.float)\n",
        "LongLatList = [[edges['N'], edges['E']],[edges['N'], edges['W']], [edges['S'], edges['E']], [edges['S'], edges['W']]]\n",
        "\n",
        "color_dict = {\n",
        "    0: 'orange',\n",
        "    1: 'red',\n",
        "    2: 'green',\n",
        "    3: 'yellow',\n",
        "    4: 'blue',\n",
        "    5: 'black',\n",
        "    6: 'gray',\n",
        "    7: 'pink',\n",
        "    8: 'brown',\n",
        "    9: 'cyan',\n",
        "}\n",
        "geos = []\n",
        "i = 1\n",
        "for i1, x in enumerate(xx):\n",
        "  for i2, y in enumerate(yy):\n",
        "    try:\n",
        "      feat = { \n",
        "              \"type\": \"Feature\",\n",
        "              \"geometry\": {\n",
        "                \"type\": \"Polygon\",\n",
        "                \"coordinates\": [\n",
        "                  [[xx[i1], yy[i2]],\n",
        "                  [xx[i1+1], yy[i2]],\n",
        "                  [xx[i1+1], yy[i2+1]],\n",
        "                  [xx[i1], yy[i2+1]]]\n",
        "                ]\n",
        "              },\n",
        "              \"properties\":\n",
        "              {\n",
        "                  \"class\": str(k_small.ravel()[i])\n",
        "              }\n",
        "      }\n",
        "      geos.append(feat)\n",
        "      i += 1\n",
        "    except IndexError:\n",
        "      pass\n",
        "\n",
        "\n",
        "geojson = { \"type\": \"FeatureCollection\",\n",
        "  \"features\": geos\n",
        "  }\n",
        "\n",
        "with open('json_data.json', 'w') as outfile:\n",
        "    json.dump(geojson, outfile)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# colors = [\"crimson\", \"purple\", \"gold\"]\n",
        "f = lambda m,c: plt.plot([],[],marker=m, color=c, ls=\"none\")[0]\n",
        "handles = [f(\"s\", color_dict[i]) for i in range(10)]\n",
        "# labels = color_dict.values()\n",
        "legend = plt.legend(handles, labels, loc=3, framealpha=1, frameon=True)\n",
        "\n",
        "def export_legend(legend, filename=\"legend.svg\", expand=[-3,-5,5,5]):\n",
        "    fig  = legend.figure\n",
        "    fig.canvas.draw()\n",
        "    bbox  = legend.get_window_extent()\n",
        "    bbox = bbox.from_extents(*(bbox.extents + np.array(expand)))\n",
        "    bbox = bbox.transformed(fig.dpi_scale_trans.inverted())\n",
        "    fig.savefig(filename, dpi=\"figure\", bbox_inches=bbox, format='svg')\n",
        "\n",
        "export_legend(legend)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "width, height = 650, 500\n",
        "m = folium.Map(location=[edges['N'], edges['E']],\n",
        "              tiles=\"cartodbpositron\",\n",
        "               zoom_start=13)\n",
        "styler = lambda x: {\n",
        "        \"fillOpacity\": 0.5,\n",
        "        \"weight\": 0,\n",
        "        \"fillColor\": color_dict[int(x['properties']['class'])],\n",
        "    }\n",
        "folium.GeoJson('./json_data.json', name=\"geojson\", style_function=styler).add_to(m)\n",
        "# folium.Choropleth(json.load(open(\"./json_data.json\"))).add_to(m)\n",
        "# folium.TopoJson(\n",
        "#     open('json_data.geojson'),\n",
        "# ).add_to(m)\n",
        "folium.LayerControl().add_to(m)\n",
        "\n",
        "legend_img = 'legend.png'\n",
        "with open(legend_img, 'rb') as lf:\n",
        "  # open in binary mode, read bytes, encode, decode obtained bytes as utf-8 string\n",
        "  b64_content = base64.b64encode(lf.read()).decode('utf-8')\n",
        "\n",
        "FloatImage('data:image/png;base64,{}'.format(b64_content), bottom=0, left=82).add_to(m)\n",
        "\n",
        "# FloatImage(image_file, bottom=50, left=0).add_to(m)\n",
        "\n",
        "m\n"
      ],
      "metadata": {
        "id": "QIqG-BOYZL26"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}